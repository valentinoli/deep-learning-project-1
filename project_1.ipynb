{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesser-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minus-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, \\\n",
    "test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from practical 4b\n",
    "def leq(x,y):\n",
    "    return x<=y\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Softmax(nb_hidden, 10)\n",
    "        #add a softmax to identify the class?\n",
    "\n",
    "    def forward(self, x_0, x_1):\n",
    "        #process the first image\n",
    "        x_0 = F.relu(F.max_pool2d(self.conv1(x_0), kernel_size=3, stride=3))\n",
    "        x_0 = F.relu(F.max_pool2d(self.conv2(x_0), kernel_size=2, stride=2))\n",
    "        x_0 = F.relu(self.fc1(x_0.view(-1, 256)))\n",
    "        x_0 = self.fc2(x_0)\n",
    "        #process the second image\n",
    "        x_1 = F.relu(F.max_pool2d(self.conv1(x_1), kernel_size=3, stride=3))\n",
    "        x_1 = F.relu(F.max_pool2d(self.conv2(x_1), kernel_size=2, stride=2))\n",
    "        x_1 = F.relu(self.fc1(x_1.view(-1, 256)))\n",
    "        x_1 = self.fc2(x_1)\n",
    "        return x_0, x_1\n",
    "    \n",
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 25):\n",
    "    #binary output\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    eta = 1e-1\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size)[:,0,:].unsqueeze(1),\n",
    "                           train_input.narrow(0, b, mini_batch_size)[:,1,:].unsqueeze(1))\n",
    "            #output=[list(output[0]), list(output[1])]\n",
    "            print(output[0])\n",
    "            output = [leq(x,y) for x, y in output]\n",
    "\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "\n",
    "            print(e, acc_loss)\n",
    "        \n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_error = 0\n",
    "    \n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size)[:,0,:].unsqueeze(1),\n",
    "                       input.narrow(0, b, mini_batch_size)[:,1,:].unsqueeze(1))\n",
    "        print(output.shape)\n",
    "        pred_class = leq(1,0)\n",
    "\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b+k, predicted_class[k]] <=0:\n",
    "                nb_error += 1\n",
    "                \n",
    "    return nb_error\n",
    "\n",
    "# weight sharing -> siamese network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=200\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "connected-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ -0.4208,  -5.4709,   6.0401, -12.2032,  12.7707,  12.4463,  -4.4911,\n",
      "         -5.9758,   5.5035,   3.2582], grad_fn=<UnbindBackward>), tensor([ 0.2838, -2.8048,  8.0472, -6.3075, 14.8049, 10.2375, -1.7444, -9.0876,\n",
      "        -2.1644,  8.5987], grad_fn=<UnbindBackward>), tensor([  3.0827,  -5.7433,   9.4372, -13.1287,  17.4882,  11.9774,  -6.7164,\n",
      "         -8.0132,   1.6518,   7.6897], grad_fn=<UnbindBackward>), tensor([ -0.0731,  -0.6275,  11.0104,  -9.2722,  16.4801,  10.4996,  -0.7556,\n",
      "        -11.2877,  -3.1023,   5.1997], grad_fn=<UnbindBackward>), tensor([  3.5514,  -3.7896,   7.5548, -11.8639,  18.4393,  13.4679,  -5.2337,\n",
      "         -8.2458,   1.0553,   7.4655], grad_fn=<UnbindBackward>), tensor([  3.2798,  -5.7587,   9.4140, -14.0973,  14.8221,  12.4307,  -5.8188,\n",
      "         -8.0522,   4.2987,   2.9037], grad_fn=<UnbindBackward>), tensor([ -0.3370,  -2.5119,   5.2385, -10.1540,  17.2144,  14.5916,  -3.2886,\n",
      "         -5.9767,   2.4920,   5.8819], grad_fn=<UnbindBackward>), tensor([ -1.0450,  -1.3796,   5.9308, -10.1458,  17.5761,  14.2281,  -2.4014,\n",
      "         -6.9738,   1.2091,   5.3257], grad_fn=<UnbindBackward>), tensor([ -0.0699,  -3.0979,   8.5069, -11.3768,  19.4815,  13.2599,  -7.4568,\n",
      "         -5.6757,   3.5054,   7.6465], grad_fn=<UnbindBackward>), tensor([  2.5547,  -5.5610,   8.9854, -12.8733,  16.2779,  13.8930,  -4.2336,\n",
      "        -10.2158,   1.9028,   6.3715], grad_fn=<UnbindBackward>), tensor([  3.5591,  -6.1519,   6.9744, -12.1843,  14.3942,  12.3587,  -5.4342,\n",
      "         -8.3186,   2.4804,   5.1348], grad_fn=<UnbindBackward>), tensor([ -0.9102,  -3.9789,  11.9517,  -9.7322,  19.9285,  13.4708,  -2.4418,\n",
      "        -11.3513,  -0.1570,   9.2263], grad_fn=<UnbindBackward>), tensor([  2.8234,  -3.3395,   9.4597, -10.7324,  15.7716,  11.5447,  -5.8202,\n",
      "        -11.8097,  -3.2895,   8.8655], grad_fn=<UnbindBackward>), tensor([  1.9028,  -4.4298,   6.0472, -11.6577,  16.6605,  12.2286,  -7.6027,\n",
      "         -6.6274,   3.3757,   8.6047], grad_fn=<UnbindBackward>), tensor([  3.2991,  -6.3126,  10.9038, -15.3697,  17.5058,  12.0873,  -6.0121,\n",
      "         -7.3859,   3.9337,   3.6097], grad_fn=<UnbindBackward>), tensor([  3.7295,  -5.9302,   9.6448, -13.6413,  15.2929,   9.8223,  -4.8908,\n",
      "         -7.7240,   3.9802,   3.2479], grad_fn=<UnbindBackward>), tensor([ -0.7444,  -3.2287,  12.8482, -10.8908,  15.3243,  10.8886,  -3.3877,\n",
      "         -5.6609,   1.2567,   1.9821], grad_fn=<UnbindBackward>), tensor([  3.7170,  -5.1587,   7.4266, -13.3030,  17.5029,  13.6800,  -6.5823,\n",
      "         -9.1983,   2.7460,   8.0492], grad_fn=<UnbindBackward>), tensor([  1.7999,  -3.4864,   9.7255,  -8.4594,  17.9816,  10.3493,  -6.4235,\n",
      "        -10.1309,  -0.2933,  11.6767], grad_fn=<UnbindBackward>), tensor([  1.3667,  -3.1582,  10.6494, -10.5472,  15.2136,  10.3461,  -1.9646,\n",
      "         -7.2115,   1.2123,   2.5091], grad_fn=<UnbindBackward>), tensor([  3.9008,  -9.0146,  10.8251, -14.6080,  18.2434,  11.8689,  -5.7264,\n",
      "        -11.0870,   2.8860,   7.0544], grad_fn=<UnbindBackward>), tensor([ 0.2644, -2.5764,  5.5215, -9.9164, 12.3584, 10.4045, -3.4492, -4.3897,\n",
      "         3.6500,  2.9255], grad_fn=<UnbindBackward>), tensor([ -0.4046,  -5.3559,  12.8420, -13.8903,  17.8784,  14.2924,  -2.7720,\n",
      "        -10.4907,   3.1769,   4.7415], grad_fn=<UnbindBackward>), tensor([  0.8752,  -6.6221,  14.6629, -13.5099,  18.3542,  13.3489,  -1.4283,\n",
      "        -10.0799,   0.1397,   3.0559], grad_fn=<UnbindBackward>), tensor([  0.1225,  -4.6047,  11.0469, -12.5935,  18.4791,  14.9932,  -1.1417,\n",
      "        -10.3615,   1.8528,   4.4418], grad_fn=<UnbindBackward>)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-a4aaeb6b7d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmini_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnb_test_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
      "\u001b[0;32m<ipython-input-89-fbe08964d0f5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target, mini_batch_size, nb_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-fbe08964d0f5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "mini_batch_size = 100\n",
    "\n",
    "train_model(model, train_input, train_target, mini_batch_size)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                  nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-station",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
